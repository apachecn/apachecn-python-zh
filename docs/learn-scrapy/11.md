# 十、理解 Scrapy 的性能



通常，很容易将性能理解错。对于 Scrapy，几乎一定会把它的性能理解错，因为这里有许多反直觉的地方。除非你对 Scrapy 的结构有清楚的了解，你会发现努力提升 Scrapy 的性能却收效甚微。这就是处理高性能、低延迟、高并发环境的复杂之处。对于优化瓶颈， Amdahl 定律仍然适用，但除非找到真正的瓶颈，吞吐量并不会增加。要想学习更多，可以看 Dr.Goldratt 的《目标》这本书，其中用比喻讲到了更多关于瓶延迟、吞吐量的知识。本章就是来帮你确认 Scrapy 配置的瓶颈所在，让你避免明显的错误。

请记住，本章相对较难，涉及到许多数学。但计算还算比较简单，并且有图表示意。如果你不喜欢数学，可以直接忽略公式，这样仍然可以搞明白 Scrapy 的性能是怎么回事。

## Scrapy 的引擎——一个直观的方法

并行系统看起来就像管道系统。在计算机科学中，我们使用队列符表示队列并处理元素（见图 1 的左边）。队列系统的基本定律是 Little 定律，它指明平衡状态下，队列系统中的总元素个数（N）等于吞吐量（T）乘以总排队/处理时间（S），即 N=T*S。另外两种形式，T=N/S 和 S=N/T 也十分有用。

![](img/5c85890389f3d7bf4500a683fc3bd775.jpg)图 1 Little 定律、队列系统、管道

管道（图 1 的右边）在几何学上也有一个相似的定律。管道的体积（V）等于长度（L）乘以横截面积（A），即 V=L*A。

如果假设 L 代表处理时间 S（L≈S），体积代表总元素个数（V≈N），横截面积啊代表吞吐量（A≈T），Little 定律和体积公式就是相同的。

> 提示：这个类比合理吗？答案是基本合理。如果我们想象小液滴在管道中以匀速流过，那么 L≈S 就完全合理，因为管道越长，液滴流过的时间也越长。V≈N 也是合理的，因为管道越大，它能容下的液滴越多。但是，我们可以通过增大压力的方法，压入更多的液滴。A≈T 是真正的类比。在管道中，吞吐量是每秒流进/流出的液滴总数，被称为体积流速，在正常的情况下，它与 A^2 成正比。这是因为更宽的管道不仅意味更多的液体流出，还具有更快的速度，因为管壁之间的空间变大了。但对于这一章，我们可以忽略这一点，假设压力和速度是不变的，吞吐量只与横截面积成正比。

Little 定律与体积公式十分相似，所以管道模型直观上是正确的。再看看图 1 中的右半部。假设管道代表 Scrapy 的下载器。第一个十分细的管道，它的总体积/并发等级（N）=8 个并发请求。长度/延迟（S）对于一个高速网站，假设为 S=250ms。现在可以计算横街面积/吞吐量 T=N/S=8/0.25=32 请求/秒。

可以看到，延迟率是手远程服务器和网络延迟的影响，不受我们控制。我们可以控制的是下载器的并发等级（N），将 8 提升到 16 或 32，如图 1 所示。对于固定的管道长度（这也不受我们控制），我们只能增加横截面积来增加体积，即增加吞吐量。用 Little 定律来讲，并发如果是 16 个请求，就有 T=N/S=16/0.25=64 请求/秒，并发 32 个请求，就有 T=N/S=32/0.25=128 请求/秒。貌似如果并发数无限大，吞吐量也就无限大。在得出这个结论之前，我们还得考虑一下串联排队系统。

## 串联排队系统

当你将横截面积/吞吐量不同的管道连接起来时，直观上，人们会认为总系统会受限于最窄的管道（最小的吞吐量 T），见图 2。

![](img/9e40644246ab8d4b1a7c0b45d685cb87.jpg)图 2 不同的串联排队系统

你还可以看到最窄的管道（即瓶颈）放在不同的地方，可以影响其他管道的填充程度。如果将填充程度类比为系统内存需求，瓶颈的摆放就十分重要了。最好能将填充程度达到最高，这样单位工作的花费最小。在 Scrapy 中，单位工作（抓取一个网页）大体包括下载器之前的一条 URL（几个字节）和下载器之后的 URL 和服务器响应。

> 提示：这就是为什么，Scrapy 把瓶颈放在下载器。

## 确认瓶颈

用管道系统的比喻，可以直观的确认瓶颈所在。查看图 2，你可以看到瓶颈之前都是满的，瓶颈之后就不是满的。

对于大多数系统，可以用系统的性能指标监测排队系统是否拥挤。通过检测 Scrapy 的队列，我们可以确定出瓶颈的所在，如果瓶颈不是在下载器的话，我们可以通过调整设置使下载器成为瓶颈。瓶颈没有得到优化，吞吐量就不会有优化。调整其它部分只会使系统变得更糟，很可能将瓶颈移到别处。所以在修改代码和配置之前，你必须找到瓶颈。你会发现在大多数情况下，包括本书中的例子，瓶颈的位置都和预想的不同。

## Scrapy 的性能模型

让我们回到 Scrapy，详细查看它的性能模型，见图 3。

![](img/7a8d06d1a9fcaf81f2b7079592467ab9.jpg)图 3 Scrapy 的性能模型

Scrapy 包括以下部分：

*   **调度器**：大量的 Request 在这里排队，直到下载器处理它们。其中大部分是 URL，因此体积不大，也就是说即便有大量请求存在，也可以被下载器及时处理。
*   **阻塞器**：这是抓取器由后向前进行反馈的一个安全阀，如果进程中的响应大于 5MB，阻塞器就会暂停更多的请求进入下载器。这可能会造成性能的波动。
*   **下载器**：这是对 Scrapy 的性能最重要的组件。它用复杂的机制限制了并发数。它的延迟（管道长度）等于远程服务器的响应时间，加上网络/操作系统、Python/Twisted 的延迟。我们可以调节并发请求数，但是对其它延迟无能为力。下载器的能力受限于 CONCURRENT_REQUESTS*设置。
*   **爬虫**：这是抓取器将 Response 变为 Item 和其它 Request 的组件。只要我们遵循规则来写爬虫，通常它不是瓶颈。
*   **Item Pipelines**：这是抓取器的第二部分。我们的爬虫对每个 Request 可能产生几百个 Items，只有 CONCURRENT_ITEMS 会被并行处理。这一点很重要，因为，如果你用 pipelines 连接数据库，你可能无意地向数据库导入数据，pipelines 的默认值（100）就会看起来很少。

爬虫和 pipelines 的代码是异步的，会包含必要的延迟，但二者不会是瓶颈。爬虫和 pipelines 很少会做繁重的处理工作。如果是的话，服务器的 CPU 则是瓶颈。

## 使用远程登录控制组件

为了理解 Requests/Items 是如何在管道中流动的，我们现在还不能真正的测量流动。然而，我们可以检测在 Scrapy 的每个阶段，有多少个 Requests/Responses/Items。

通过 Scrapy 运行远程登录，我们就可以得到性能信息。我们可以在 6023 端口运行远程登录命令。然后，会在 Scrapy 中出现一个 Python 控制台。注意，如果在这里进行中断操作，比如 time.sleep()，就会暂停爬虫。通过内建的 est()函数，可以查看一些有趣的信息。其中一些或是非常专业的，或是可以从核心数据推导出来。本章后面会展示后者。下面运行一个例子。当我们运行一个爬虫时，我们在开发机打开第二台终端，在端口 6023 远程登录，然后运行 est()。

> 提示：本章代码位于目录 ch10。这个例子位于 ch10/speed。

在第一台终端，运行如下命令：

```py
$ pwd
/root/book/ch10/speed
$ ls
scrapy.cfg  speed
$ scrapy crawl speed -s SPEED_PIPELINE_ASYNC_DELAY=1
INFO: Scrapy 1.0.3 started (bot: speed)
... 
```

现在先不关注 scrapy crawl speed 和它的参数的意义，后面会详解。在第二台终端，运行如下代码：

```py
$ telnet localhost 6023
>>> est()
...
len(engine.downloader.active)                   : 16
...
len(engine.slot.scheduler.mqs)                  : 4475
...
len(engine.scraper.slot.active)                 : 115
engine.scraper.slot.active_size                 : 117760
engine.scraper.slot.itemproc_size               : 105 
```

然后在第二台终端按 Ctrl+D 退出远程登录，返回第一台终端按 Ctrl+C 停止抓取。

> 提示：我们现在忽略 dqs。如果你通过设置 JOBDIR 打开了持久支持，你会得到非零的 dqs（len(engine.slot.scheduler.dqs)），你应该将它添加到 mqs 的大小中。

让我们查看这个例子中的数据的意义。mqs 指出调度器中等待的项目很少（4475 个请求）。len(engine.downloader.active)指出下载器现在正在下载 16 个请求。这与我们在 CONCURRENT_REQUESTS 的设置相同。len(engine.scraper.slot.active)说明现在正有 115 个响应在抓取器中处理。 (engine.scraper.slot.active_size)告诉我们这些响应的大小是 115kb。除了响应，105 个 Items 正在 pipelines(engine.scraper.slot.itemproc_size)中处理，这说明还有 10 个在爬虫中。经过总结，我们看到瓶颈是下载器，在下载器之前有很长的任务队列（mqs），下载器在满负荷运转；下载器之后，工作量较高并有一定波动。

另一个可以查看信息的地方是 stats 对象，抓取之后打印的内容。我们可以以 dict 的形式访问它，只需通过 via stats.get_stats()远程登录，用 p()函数打印：

```py
$ p(stats.get_stats())
{'downloader/request_bytes': 558330,
...
 'item_scraped_count': 2485,
...} 
```

这里对我们最重要的是 item_scraped_count，它可以通过 stats.get_value ('item_scraped_count')之间访问。它告诉我们现在已经抓取了多少个 items，以及增长的速率，即吞吐量。

## 评分系统

我为本章写了一个简单的评分系统，它可以让我们评估在不同场景下的性能。它的代码有些复杂，你可以在 speed/spiders/speed.py 找到，但我们不会深入讲解它。

这个评分系统包括：

*   服务器上[http://localhost:9312/benchmark/](https://link.jianshu.com?t=http://localhost:9312/benchmark/)...的句柄（handlers）。我们可以控制这个假网站的结构（见图 4），通过调节 URL 参数/Scrapy 设置，控制网页加载的速度。不用在意细节，我们接下来会看许多例子。现在，先看一下[http://localhost:9312/benchmark/index?p=1](https://link.jianshu.com?t=http://localhost:9312/benchmark/index?p=1)和[http://localhost:9312/benchmark/id:3/rr:5/index?p=1](https://link.jianshu.com?t=http://localhost:9312/benchmark/id:3/rr:5/index?p=1)的不同。第一个网页在半秒内加载完毕，每页只含有一个 item，第二个网页加载用了五秒，每页有三个 items。我们还可以在网页上添加垃圾信息，降低加载速度。例如，查看[http://localhost:9312/benchmark/ds:100/detail?id0=0](https://link.jianshu.com?t=http://localhost:9312/benchmark/ds:100/detail?id0=0)。默认条件下（见 speed/[settings.py](https://link.jianshu.com?t=http://settings.py)），页面渲染用时 SPEED_T_RESPONSE = 0.125 秒，假网站有 SPEED_TOTAL_ITEMS = 5000 个 Items。

![](img/675b9ba463c6c72def3541c2f7c3232c.jpg)图 4 评分服务器创建了一个结构可变的假网站

*   爬虫，SpeedSpider，模拟用几种方式取回被 SPEED_START_REQUESTS_STYLE 控制的 start_requests()，并给出一个 parse_item()方法。默认下，用 crawler.engine.crawl()方法将所有起始 URL 提供给调度器。
*   pipeline，DummyPipeline，模拟了一些处理过程。它可以引入四种不同的延迟类型。阻塞/计算/同步延迟(SPEED_PIPELINE_BLOCKING_DELAY—很差)，异步延迟(SPEED_PIPELINE_ASYNC_DELAY—不错)，使用远程 treq 库进行 API 调用(SPEED_PIPELINE_API_VIA_TREQ—不错)，和使用 Scrapy 的 crawler.engine.download()进行 API 调用(SPEED_PIPELINE_API_VIA_DOWNLOADER—不怎么好)。默认时，pipeline 不添加延迟。
*   settings.py 中的一组高性能设置。关闭任何可能使系统降速的项。因为只在本地服务器运行，我们还关闭了每个域的请求限制。
*   一个可以记录数据的扩展，和第 8 章中的类似。它每隔一段时间，就打印出核心数据。

在上一个例子，我们已经用过了这个系统，让我们重新做一次模拟，并使用 Linux 的计时器测量总共的执行时间。核心数据打印如下：

```py
$ time scrapy crawl speed
...
INFO:  s/edule  d/load  scrape  p/line    done       mem
INFO:        0       0       0       0       0         0
INFO:     4938      14      16       0      32     16384
INFO:     4831      16       6       0     147      6144
...
INFO:      119      16      16       0    4849     16384
INFO:        2      16      12       0    4970     12288
...
real  0m46.561s
Column          Metric
s/edule         len(engine.slot.scheduler.mqs)
d/load          len(engine.downloader.active)
scrape          len(engine.scraper.slot.active)
p/line          engine.scraper.slot.itemproc_size
done            stats.get_value('item_scraped_count')
mem             engine.scraper.slot.active_size 
```

结果这样显示出来效果很好。调度器中初始有 5000 条 URL，结束时 done 的列也有 5000 条。下载器全负荷下并发数是 16，与设置相同。抓取器主要是爬虫，因为 pipeline 是空的，它没有满负荷运转。它用 46 秒抓取了 5000 个 Items，并发数是 16，即每个请求的处理时间是 46*16/5000=147ms，而不是预想的 125ms，满足要求。

## 标准性能模型

当 Scrapy 正常运行且下载器为瓶颈时，就是 Scrapy 的标准性能模型。此时，调度器有一定数量的请求，下载器满负荷运行。抓取器负荷不满，并且加载的响应不会持续增加。

![](img/78dd9bc4255fefa4eb235ce8ab8b2be1.jpg)图 5 标准性能模型和一些试验结果

三项设置负责控制下载器的性能： CONCURRENT_REQUESTS，CONCURRENT_REQUESTS_PER_DOMAIN 和 CONCURRENT_REQUESTS_PER_IP。第一个是宏观上的控制，无论任何时候，并发数都不能超过 CONCURRENT_REQUESTS。另外，如果是单域或几个域，CONCURRENT_REQUESTS_PER_DOMAIN 也可以限制活跃请求数。如果你设置了 CONCURRENT_REQUESTS_PER_IP，CONCURRENT_REQUESTS_PER_DOMAIN 就会被忽略，活跃请求数就是每个 IP 的请求数量。对于共享站点，比如，多个域名指向一个服务器，这可以帮助你降低服务器的载荷。

为了更简明的分析，现在把 per-IP 的限制关闭，即使 CONCURRENT_REQUESTS_PER_IP 为默认值（0），并设置 CONCURRENT_REQUESTS_PER_DOMAIN 为一个超大值（1000000）。这样就可以无视其它的设置，让下载器的并发数完全受 CONCURRENT_REQUESTS 控制。

我们希望吞吐量取决于下载网页的平均时间，包括远程服务器和我们系统（Linux、Twisted/Python）的延迟，t<sub>download</sub>=t<sub>response</sub>+t<sub>overhead</sub>。还可以加上启动和关闭的时间。这包括从取得响应到 Items 离开 pipeline 的时间，和取得第一个响应的时间，还有空缓存的内部损耗。

总之，如果你要完成 N 个请求，在爬虫正常的情况下，需要花费的时间是：

![](img/7340a2fa5cc3db21133ee8eda503815c.jpg)

所幸的是，我们只需控制一部分参数就可以了。我们可以用一台更高效的服务器控制 t<sub>overhead</sub>，和 t<sub>start/stop</sub>，但是后者并不值得，因为每次运行只影响一次。除此之外，最值得关注的就是 CONCURRENT_REQUESTS，它取决于我们如何使用服务器。如果将其设置成一个很大的值，在某一时刻就会使服务器或我们电脑的 CPU 满负荷，这样响应就会不及时，t<sub>response</sub>会急剧升高，因为网站会阻塞、屏蔽进一步的访问，或者服务器会崩溃。

让我们验证一下这个理论。我们抓取 2000 个 items，t<sub>response</sub>∈{0.125s，0.25s，0.5s}，CONCURRENT_REQUESTS∈{8，16，32，64}：

```py
$ for delay in 0.125 0.25 0.50; do for concurrent in 8 16 32 64; do
    time scrapy crawl speed -s SPEED_TOTAL_ITEMS=2000 \
    -s CONCURRENT_REQUESTS=$concurrent -s SPEED_T_RESPONSE=$delay
  done; done 
```

在我的电脑上，我完成 2000 个请求的时间如下：

![](img/24c454c4e09d2a378d28bf533b762e0c.jpg)

接下来复杂的数学推导，可以跳过。在图 5 中，可以看到一些结果。将上一个公式变形为 y=t<sub>overhead</sub>·x+ t<sub>start/stop</sub>，其中 x=N/CONCURRENT_REQUESTS， y=t<sub>job</sub>·x+t<sub>response</sub>。使用最小二乘法（LINEST Excel 函数）和前面的数据，可以计算出 t<sub>overhead</sub>=6ms，t<sub>start/stop</sub>=3.1s。toverhead 可以忽略，但是开始时间相对较长，最好是在数千条 URL 时长时间运行。因此，可以估算出吞吐量公式是：

![](img/09fd06cb73c76b6b5e3bb03417997f78.jpg)

处理 N 个请求，我们可以估算 t<sub>job</sub>，然后可以直接求出 T。

## 解决性能问题

现在我们已经明白如何使 Scrapy 的性能最大化，让我们来看看如何解决实际问题。我们会通过探究症状、运行错误、讨论原因、修复问题，讨论几个实例。呈现的顺序是从系统性的问题到 Scrapy 的小技术问题，也就是说，更为常见的问题可能会排在后面。请阅读全部章节，再开始处理你自己的问题。

## 实例 1——CPU 满负荷

症状：当你提高并发数时，性能并没有提高。当你降低并发数，一切工作正常。下载器没有问题，但是每个请求花费时间太长。用 Unix/Linux 命令 ps 或 Windows 的任务管理器查看 CPU 的情况，CPU 的占用率非常高。

案例：假设你运行如下命令：

```py
$ for concurrent in 25 50 100 150 200; do
   time scrapy crawl speed -s SPEED_TOTAL_ITEMS=5000 \
    -s CONCURRENT_REQUESTS=$concurrent
  done 
```

求得抓取 5000 条 URL 的时间。预计时间是用之前推导的公式求出的，CPU 是用命令查看得到的（可以在另一台终端运行查看命令）：

![](img/745cb8623aaf6ec389c4cdcb025c9a3c.jpg)![](img/8b13f3109d77546f0084b9a75c721f12.jpg)图 6 当并发数超出一定值时，性能变化趋缓。

在我们的试验中，我们没有进行任何处理工作，所以并发数可以很高。在实际中，很快就可以看到性能趋缓的情况发生。

讨论：Scrapy 使用的是单线程，当并发数很高时，CPU 可能会成为瓶颈。假设没有使用线程池，CPU 的使用率建议是 80-90%。可能你还会碰到其他系统性问题，比如带宽、内存、硬盘吞吐量，但是发生这些状况的可能性比较小，并且不属于系统管理，所以就不赘述了。

解决：假设你的代码已经是高效的。你可以通过在一台服务器上运行多个爬虫，使累积并发数超过 CONCURRENT_REQUESTS。这可以充分利用 CPU 的性能。如果还想提高并发数，你可以使用多台服务器（见 11 章），这样就可以使用更多的内存、带宽和硬盘吞吐量。检查 CPU 的使用情况是你的首要关切。

## 实例 2-阻塞代码

症状：系统的运行得十分奇怪。比起预期的速度，系统运行的十分缓慢。改变并发数，也没有效果。下载器几乎是空的（远小于并发数），抓取器的响应数很少。

案例：使用两个评分设置，SPEED_SPIDER_BLOCKING_DELAY 和 SPEED_PIPELINE_BLOCKING_DELAY（二者效果相同），使每个响应有 100ms 的阻塞延迟。在给定的并发数下，100 条 URL 大概要 2 到 3 秒，但结果总是 13 秒左右，并且不受并发数影响：

```py
for concurrent in 16 32 64; do
  time scrapy crawl speed -s SPEED_TOTAL_ITEMS=100 \
  -s CONCURRENT_REQUESTS=$concurrent -s SPEED_SPIDER_BLOCKING_DELAY=0.1
done 
```

![](img/d5efa5141e985c794906203a96d9241d.jpg)

讨论：任何阻塞代码都会是并发数无效，并使得 CONCURRENT_REQUESTS=1。公式：100URL*100ms(阻塞延迟)=10 秒+tstart/stop，完美解释了发生的状况。

![](img/7fb52ea5be780e67a3bc6ee59ae0374e.jpg)图 7 阻塞代码使并发数无效化

无论阻塞代码位于 pipelines 还是爬虫，你都会看到抓取器满负荷，它之前和之后的部分都是空的。看起来这违背了我们之前讲的，但是由于我们并没有一个并行系统，pipeline 的规则此处并不适用。这个错误很容易犯（例如，使用了阻塞 APIs），然后就会出现之前的状况。相似的讨论也适用于计算复杂的代码。应该为每个代码使用多线程，如第 9 章所示，或在 Scrapy 的外部批次运行，第 11 章会看到例子。

解决：假设代码是继承而来的，你并不知道阻塞代码位于何处。没有 pipelines 系统也能运行的话，使 pipeline 无效，看系统能否正常运行。如果是的话，说明阻塞代码位于 pipelines。如果不是的话，逐一恢复 pipelines，看问题何时发生。如果必须所有组件都在运行，整个系统才能运行的话，给每个 pipeline 阶段添加日志消息（或者插入可以打印时间戳的伪 pipelines），就可以发现哪一步花费的时间最多。如果你想要一个长期可重复使用的解决方案，你可以用在每个 meta 字段添加时间戳的伪 pipelines 追踪请求。最后，连接 item_scraped 信号，打印出时间戳。一旦找到阻塞代码，将其转化为 Twisted/异步，或使用 Twisted 的线程池。要查看转化的效果，将 SPEED_PIPELINE_BLOCKING_DELAY 替换为 SPEED_PIPELINE_ASYNC_DELAY，然后再次运行。可以看到性能改进很大。

## 实例 3-下载器中有“垃圾”

症状：吞吐量比预期的低。下载器的请求数貌似比并发数多。

案例：模拟下载 1000 个网页，每个响应时间是 0.25 秒。当并发数是 16 时，根据公式，整个过程大概需要 19 秒。我们使用一个 pipeline，它使用 crawler.engine.download()向一个响应时间小于一秒的伪装 API 做另一个 HTTP 请求，。你可以在[http://localhost:9312/benchmark/ar:1/api?text=hello](https://link.jianshu.com?t=http://localhost:9312/benchmark/ar:1/api?text=hello)尝试。下面运行爬虫：

```py
$ time scrapy crawl speed -s SPEED_TOTAL_ITEMS=1000 -s SPEED_T_
RESPONSE=0.25 -s SPEED_API_T_RESPONSE=1 -s SPEED_PIPELINE_API_VIA_
DOWNLOADER=1
...
s/edule  d/load  scrape  p/line    done       mem
    968      32      32      32       0     32768
    952      16       0       0      32         0
    936      32      32      32      32     32768
...
real 0m55.151s 
```

很奇怪，不仅时间多花了三倍，并发数也比设置的数值 16 要大。下载器明显是瓶颈，因为它已经过载了。让我们重新运行爬虫，在另一台终端，远程登录 Scrapy。然后就可以查看下载器中运行的 Requests 是哪个：

```py
$ telnet localhost 6023
>>> engine.downloader.active
set([<POST http://web:9312/ar:1/ti:1000/rr:0.25/benchmark/api>,  ... ]) 
```

貌似下载器主要是在做 APIs 请求，而不是下载网页。

讨论：你可能希望没人使用 crawler.engine.download()，因为它看起来很复杂，但在 Scrapy 的 robots.txt 中间件和媒体 pipeline，它被使用了两次。因此，当人们需要处理网络 APIs 时，自然而然要使用它。使用它远比使用阻塞 APIs 要好，例如前面看过的流行的 Python 的 requests 包。比起理解 Twisted 和使用 treq，它使用起来也更简单。这个错误很难调试，所以让我们转而查看下载器中的请求。如果看到有 API 或媒体 URL 不是直接抓取的，就说明 pipelines 使用了 crawler.engine.download()进行了 HTTP 请求。我们的 ONCURRENT_REQUESTS 限制部队这些请求生效，所以下载器中的请求数总是超过设置的并发数。除非伪请求数小于 CONCURRENT_REQUESTS，下载器不会从调度器取得新的网页请求。

![](img/4d56af7a260cf54e598382558d7c9e5d.jpg)图 8 伪 API 请求决定了性能

因此，当原始请求持续 1 秒（API 延迟）而不是 0.25 秒时（页面下载延迟），吞吐量自然会发生变化。这里容易让人迷惑的地方是，要是 API 的调用比网页请求还快，我们根本不会观察到性能的下降。

解决：我们可以使用 treq 而不是 crawler.engine.download()解决这个问题，你可以看到抓取器的性能大幅提高，这对 API 可能不是个好消息。我先将 CONCURRENT_REQUESTS 设置的很低，然后逐步提高，以确保不让 API 服务器过载。

下面是使用 treq 的例子：

```py
$ time scrapy crawl speed -s SPEED_TOTAL_ITEMS=1000 -s SPEED_T_
RESPONSE=0.25 -s SPEED_API_T_RESPONSE=1 -s SPEED_PIPELINE_API_VIA_TREQ=1
...
s/edule  d/load  scrape  p/line    done       mem
    936      16      48      32       0     49152
    887      16      65      64      32     66560
    823      16      65      52      96     66560
...
real 0m19.922s 
```

可以看到一个有趣的现象。pipeline (p/line)的 items 似乎比下载器(d/load)的还多。这并不是一个问题，弄清楚它是很有意思的。

![](img/3ebf881419c810ad29b4c89ab7e7e060.jpg)图 9 使用长 pipelines 也符合要求

和预期一样，下载器中有 16 条请求。这意味着系统的吞吐量是 T = N/S = 16/0.25 = 64 请求/秒。done 这一列逐渐升高，可以确认这点。每条请求在下载器中耗时 0.25 秒，但它在 pipelines 中会耗时 1 秒，因为较慢的 API 请求。这意味着在 pipeline 中，平均的 N = T * S = 64 * 1 = 64 Items。这完全合理。这是说 pipelines 是瓶颈吗？不是，因为 pipelines 没有同时处理响应数量的限制。只要这个数字不持续增加，就没有问题。接下来会进一步讨论。

## 实例 4-大量响应造成溢出

症状：下载器几乎满负荷运转，一段时间后关闭。这种情况循环发生。抓取器的内存使用很高。

案例：设置和以前相同（使用 treq），但响应很高，有大约 120kB 的 HTML。可以看到，这次耗时 31 秒而不是 20 秒：

```py
$ time scrapy crawl speed -s SPEED_TOTAL_ITEMS=1000 -s SPEED_T_
RESPONSE=0.25 -s SPEED_API_T_RESPONSE=1 -s SPEED_PIPELINE_API_VIA_TREQ=1 
-s SPEED_DETAIL_EXTRA_SIZE=120000
s/edule  d/load  scrape  p/line    done       mem
    952      16      32      32       0   3842818
    917      16      35      35      32   4203080
    876      16      41      41      67   4923608
    840       4      48      43     108   5764224
    805       3      46      27     149   5524048
...
real  0m30.611s 
```

讨论：我们可能简单的认为延迟的原因是“需要更多的时间创建、传输、处理网页”，但这并不是真正的原因。对于响应的大小有一个强制性的限制，max_active_size = 5000000。每一个响应都和响应体的大小相同，至少为 1kB。

![](img/eb416cfba996e61f7509e9a3150dc635.jpg)图 10 下载器中的请求数不规律变化，说明存在响应大小限制

这个限制可能是 Scrapy 最基本的机制，当存在慢爬虫和 pipelines 时，以保证性能。如果 pipelines 的吞吐量小于下载器的吞吐量，这个机制就会起作用。当 pipelines 的处理时间很长，即便是很小的响应也可能触发这个机制。下面是一个极端的例子，pipelines 非常长，80 秒后出现问题：

```py
$ time scrapy crawl speed -s SPEED_TOTAL_ITEMS=10000 -s SPEED_T_
RESPONSE=0.25 -s SPEED_PIPELINE_ASYNC_DELAY=85 
```

解决：对于这个问题，在底层结构上很难做什么。当你不再需要响应体的时候，可以立即清除它。这可能是在爬虫的后续清除响应体，但是这么做不会重置抓取器的计数器。你能做的是减少 pipelines 的处理时间，减少抓取器中的响应数量。用传统的优化方法就可以做到：检查交互中的 APIs 或数据库是否支持抓取器的吞吐量，估算下载器的能力，将 pipelines 进行后批次处理，或使用性能更强的服务器或分布式抓取。

## 实例 5-item 并发受限/过量造成溢出

症状：爬虫对每个响应产生多个 Items。吞吐量比预期的小，和之前的实例相似，也呈现出间歇性。

案例：我们有 1000 个请求，每一个会返回 100 个 items。响应时间是 0.25 秒，pipelines 处理时间是 3 秒。进行几次试验，CONCURRENT_ITEMS 的范围是 10 到 150：

```py
for concurrent_items in 10 20 50 100 150; do
time scrapy crawl speed -s SPEED_TOTAL_ITEMS=100000 -s  \
SPEED_T_RESPONSE=0.25 -s SPEED_ITEMS_PER_DETAIL=100 -s  \
SPEED_PIPELINE_ASYNC_DELAY=3 -s \
CONCURRENT_ITEMS=$concurrent_items
done
...
s/edule  d/load  scrape  p/line    done       mem
    952      16      32     180       0    243714
    920      16      64     640       0    487426
    888      16      96     960       0    731138
... 
```

![](img/4a8d58738384fdb0bcbb83111427410d.jpg)图 11 以 CONCURRENT_ITEMS 为参数的抓取时间函数

讨论：只有每个响应产生多个 Items 时才出现这种情况。这个案例的人为性太强，因为吞吐量达到了每秒 1300 个 Items。吞吐量这么高是因为稳定的低延迟、没进行处理、响应很小。这样的条件很少见。

我们首先观察到的是，以前 scrape 和 p/line 两列的数值是相同的，现在 p/line 显示的是 shows CONCURRENT_ITEMS * scrape。这是因为 scrape 显示 Reponses，而 p/line 显示 Items。

第二个是图 11 中像一个浴缸的函数。部分原因是纵坐标轴造成的。在左侧，有非常高延迟，因为达到了内存极限。右侧，并发数太大，CPU 使用率太高。取得最优化并不是那么重要，因为很容易向左或向右变动。

解决：很容易检测出这个例子中的两个错误。如果 CPU 使用率太高，就降低并发数。如果达到了 5MB 的响应限制，pipelines 就不能很好的衔接下载器的吞吐量，提高并发数就可以解决。如果不能解决问题，就查看一下前面的解决方案，并审视是否系统的其它部分可以支撑抓取器的吞吐量。

## 实例 6-下载器没有充分运行

症状：提高了 CONCURRENT_REQUESTS，但是下载器中的数量并没有提高，并且没有充分利用。调度器是空的。

案例：首先运行一个没有问题的例子。将响应时间设为 1 秒，这样可以简化计算，使下载器吞吐量 T = N/S = N/1 = CONCURRENT_REQUESTS。然后运行如下代码：

```py
$ time scrapy crawl speed -s SPEED_TOTAL_ITEMS=500 \
-s SPEED_T_RESPONSE=1 -s CONCURRENT_REQUESTS=64
  s/edule  d/load  scrape  p/line    done       mem
     436      64       0       0       0         0
...
real  0m10.99s 
```

下载器满状态运行（64 个请求），总时长为 11 秒，和 500 条 URL、每秒 64 请求的模型相符，S=N/T+tstart/stop=500/64+3.1=10.91 秒。
现在，再做相同的抓取，不再像之前从列表中提取 URL，这次使用 SPEED_START_REQUESTS_STYLE=UseIndex 从索引页提取 URL。这与其它章的方法是一样的。每个索引页有 20 条 URL：

```py
$ time scrapy crawl speed -s SPEED_TOTAL_ITEMS=500 \
-s SPEED_T_RESPONSE=1 -s CONCURRENT_REQUESTS=64 \
-s SPEED_START_REQUESTS_STYLE=UseIndex
s/edule  d/load  scrape  p/line    done       mem
       0       1       0       0       0         0
       0      21       0       0       0         0
       0      21       0       0      20         0
...
real 0m32.24s 
```

很明显，与之前的结果不同。下载器没有满负荷运行，吞吐量为 T=N/S-tstart/stop=500/(32.2-3.1)=17 请求/秒。

讨论：d/load 列可以确认下载器没有满负荷运行。这是因为没有足够的 URL 进入。抓取过程产生 URL 的速度慢于处理的速度。这时，每个索引页会产生 20 个 URL+下一个索引页。吞吐量不可能超过每秒 20 个请求，因为产生 URL 的速度没有这么快。

解决：如果每个索引页有至少两个下一个索引页的链接，呢么我们就可以加快产生 URL 的速度。如果可以找到能产生更多 URL（例如 50）的索引页面则会更好。通过模拟观察变化：

```py
$ for details in 10 20 30 40; do for nxtlinks in 1 2 3 4; do
time scrapy crawl speed -s SPEED_TOTAL_ITEMS=500 -s SPEED_T_RESPONSE=1 \
-s CONCURRENT_REQUESTS=64 -s SPEED_START_REQUESTS_STYLE=UseIndex \
-s SPEED_DETAILS_PER_INDEX_PAGE=$details \
-s SPEED_INDEX_POINTAHEAD=$nxtlinks
done; done 
```

![](img/fad9c1665058ab5cce0d755ba154ae0a.jpg)图 12 以每页能产生的链接数为参数的吞吐量函数

在图 12 中，我们可以看到吞吐量是如何随每页 URL 数和索引页链接数变化的。初始都是线性变化，直到到达系统限制。你可以改变爬虫的规则进行试验。如果使用 LIFO（默认项）规则，即先发出索引页请求最后收回，可以看到性能有小幅提高。你也可以将索引页的优先级设置为最高。两种方法都不会有太大的提高，但是你可以通过分别设置 SPEED_INDEX_RULE_LAST=1 和 SPEED_INDEX_HIGHER_PRIORITY=1，进行试验。请记住，这两种方法都会首先下载索引页（因为优先级高），因此会在调度器中产生大量 URL，这会提高对内存的要求。在完成索引页之前，输出的结果很少。索引页不多时推荐这种做法，有大量索引时不推荐这么做。

另一个简单但高效的方法是分享首页。这需要你使用至少两个首页 URL，并且它们之间距离最大。例如，如果首页有 100 页，你可以选择 1 和 51 作为起始。爬虫这样就可以将抓取下一页的速度提高一倍。相似的，对首页中的商品品牌或其他属性也可以这么做，将首页大致分为两个部分。你可以使用-s SPEED_INDEX_SHARDS 设置进行模拟：

```py
$ for details in 10 20 30 40; do for shards in 1 2 3 4; do
time scrapy crawl speed -s SPEED_TOTAL_ITEMS=500 -s SPEED_T_RESPONSE=1 \
-s CONCURRENT_REQUESTS=64 -s SPEED_START_REQUESTS_STYLE=UseIndex \
-s SPEED_DETAILS_PER_INDEX_PAGE=$details -s SPEED_INDEX_SHARDS=$shards
done; done 
```

这次的结果比之前的方法要好，并且更加简洁 。

## 解决问题的流程

总结一下，Scrapy 的设计初衷就是让下载器作为瓶颈。使 CONCURRENT_REQUESTS 从小开始，逐渐变大，直到发生以下的限制：

*   CPU 利用率 > 80-90%
*   源网站延迟急剧升高
*   抓取器的响应达到内存 5Mb 上限
    同时，进行如下操作：
*   始终保持调度器（mqs/dqs）中有一定数量的请求，避免下载器是空的
*   不使用阻塞代码或 CPU 密集型代码

![](img/3af65ddee0d38d3ae0dca08bff910b37.jpg)图 13 解决 Scrapy 性能问题的路线图

## 总结

在本章中，我们通过案例展示了 Scrapy 的架构是如何影响性能的。细节可能会在未来的 Scrapy 版本中变动，但是本章阐述的原理在相当长一段时间内可以帮助你理解以 Twisted、Netty Node.js 等为基础的异步框架。

谈到具体的 Scrapy 性能，有三个确定的答案：我不知道也不关心、我不知道但会查出原因，和我知道。本章已多次指出，“更多的服务器/内存/带宽”不能提高 Scrapy 的性能。唯一的方法是找到瓶颈并解决它。

在最后一章中，我们会学习如何进一步提高性能，不是使用一台服务器，而是在多台服务器上分布多个爬虫。

