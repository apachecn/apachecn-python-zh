# 算法设计原则

我们为什么要研究算法设计？当然，原因有很多，我们学习东西的动机很大程度上取决于我们自己的环境。毫无疑问，对算法设计感兴趣有着重要的专业原因。算法是所有计算的基础。我们可以把计算机看作是一块硬件，有硬盘、内存芯片、处理器等等。然而，算法是最基本的组成部分，如果缺失了它，将使现代技术变得不可能。让我们在接下来的部分中了解更多。

在本章中，我们将研究以下主题：

*   算法简介
*   递归与回溯
*   大 O 符号

# 技术要求

我们需要用 Python 安装`matplotlib`库来绘制本章中的图表

通过在终端上运行以下命令，可以将其安装在 Ubuntu/Linux 上：

```py
python3 -mpip install matplotlib
```

您还可以使用以下选项：

```py
sudo apt-get install python3-matplotlib 
```

要在 Windows 上安装`matplotlib`：

如果 Python 已经安装在 Windows 操作系统上，可以通过以下链接获取`matplotlib`在 Windows 上安装：[https://github.com/matplotlib/matplotlib/downloads](https://github.com/matplotlib/matplotlib/downloads) 或[https://matplotlib.org](https://matplotlib.org) 。

本章代码文件可在以下网址找到：[https://github.com/PacktPublishing/Hands-On-Data-Structures-and-Algorithms-with-Python-Second-Edition/tree/master/Chapter03](https://github.com/PacktPublishing/Hands-On-Data-Structures-and-Algorithms-with-Python-Second-Edition/tree/master/Chapter03) 。

# 算法简介

算法的理论基础，以图灵机的形式，在数字逻辑电路实际上可以实现这样的机器之前建立了几十年。图灵机本质上是一个数学模型，它使用一组预定义的规则将一组输入转换为一组输出。图灵机的第一个实现是机械的，下一代可能会看到数字逻辑电路被量子电路或类似的东西所取代。无论平台是什么，算法都起着核心的主导作用。

另一个方面是算法对技术创新的影响。作为一个明显的例子，考虑页面排名搜索算法，谷歌搜索引擎基于它的变化。使用这种和类似的算法可以让研究人员、科学家、技术人员和其他人以极快的速度快速搜索大量信息。这对新研究、新发现和新创新技术的发展速度有着巨大的影响。算法是执行特定任务的一组连续指令。它们非常重要，因为我们可以把一个复杂的问题分解成一个较小的问题，准备简单的步骤来执行一个大问题，而这个问题是算法中最重要的部分。一个好的算法是一个高效的程序解决特定问题的关键。算法的研究也很重要，因为它训练我们非常具体地思考某些问题。它可以通过隔离问题的组成部分并定义这些组成部分之间的关系来帮助提高我们解决问题的能力。总之，研究算法有一些重要原因：

*   它们对于计算机科学和*智能*系统至关重要
*   它们在许多其他领域（计算生物学、经济学、生态学、通信、生态学、物理学等）都很重要
*   它们在技术创新中发挥作用
*   他们提高了解决问题和分析思维能力

解决给定问题主要有两个重要方面。首先，我们需要一种有效的机制来存储、管理和检索数据，这对于解决问题很重要（这属于数据结构）；其次，我们需要一个有效的算法，它是一组有限的指令来解决这个问题。因此，研究数据结构和算法是使用计算机程序解决任何问题的关键。有效的算法应具有以下特点：

*   它应该尽可能具体
*   它应该正确定义每个指令
*   不应该有任何模棱两可的指示
*   算法的所有指令都应该在有限的时间内和有限的步骤内执行
*   它应该有明确的输入和输出来解决问题
*   算法的每条指令在解决给定问题时都应该很重要

算法，以其最简单的形式，只是一系列操作——一系列指令。它可能只是一个线性构造，形式为 do*x*，然后执行*y*，然后执行*z*，然后完成。然而，为了使事情变得更有用，我们在 do*x*之后添加了子句 do*y*；在 Python 中，这些是 if-else 语句。在这里，未来的行动方针取决于某些条件；比如说数据结构的状态。为此，我们还添加了操作、迭代、while 和 for 语句。进一步扩展我们的算法知识，我们添加了递归。递归通常可以获得与迭代相同的结果，但是，它们是根本不同的。递归函数调用自身，将相同的函数应用于逐渐减小的输入。任何递归步骤的输入都是前一个递归步骤的输出。

# 算法设计范例

一般来说，我们可以区分三种广泛的算法设计方法。他们是：

*   分而治之
*   贪婪算法
*   动态规划

顾名思义，分而治之的范式包括将一个问题分解成更小的简单子问题，然后解决这些子问题，最后结合结果获得全局最优解。这是一种非常常见和自然的问题解决技术，可以说是算法设计中最常用的方法。例如，合并排序是一种对 n 个自然数的列表进行递增排序的算法。

在该算法中，我们迭代地将列表分成相等的部分，直到每个子列表包含一个元素，然后我们将这些子列表组合起来，以排序顺序创建一个新列表。我们将在本节/章节后面更详细地讨论合并排序。

分治算法范例的一些示例如下：

*   二进制搜索
*   合并排序
*   快速排序
*   快速乘法的 Karatsuba 算法
*   斯特拉森矩阵乘法
*   最近点对

贪婪算法通常涉及优化和组合问题。在贪心算法中，目标是从每一步的许多可能解中获得最佳解，并试图获得局部最优解，从而最终获得整体最优解。通常，贪婪算法用于优化问题。这里有许多流行的标准问题，我们可以使用贪婪算法来获得最佳解决方案：

*   Kruskal 最小生成树
*   Dijkstra 最短路径
*   背包问题
*   Prim 最小生成树算法
*   旅行商问题

贪婪算法通常涉及优化和组合问题；经典的例子是将贪婪算法应用于旅行推销员问题，其中贪婪方法总是首先选择最近的目的地。这种最短路径策略包括找到局部问题的最佳解决方案，希望这将导致一个全局解决方案。

另一个经典的例子是将贪婪算法应用于旅行推销员问题；这是一个 NP 难问题。在这个问题中，贪婪方法总是首先从当前城市中选择最近的未访问城市；通过这种方式，我们不确定我们是否得到了最佳解决方案，但我们肯定得到了最佳解决方案。这种最短路径策略包括找到局部问题的最佳解决方案，希望这将导致一个全局解决方案。

当子问题重叠时，动态规划方法很有用。这不同于分而治之。与将问题分解为独立的子问题不同，通过动态规划，中间结果被缓存并可用于后续操作。像分治一样，它使用递归；然而，动态规划允许我们比较不同阶段的结果。对于某些问题，这可能比分而治之具有性能优势，因为从内存中检索以前计算的结果通常比重新计算结果更快。动态规划也使用递归来解决问题。例如，矩阵链乘法问题可以用动态规划来解决。矩阵链乘法问题确定了矩阵乘法的最佳有效方法。当给定矩阵序列时，它会找到需要最少运算次数的乘法顺序。

例如，让我们看三个矩阵-*P*、*Q*和*R*。为了计算这三个矩阵的乘法，我们有许多可能的选择（因为矩阵乘法是关联的），例如*（PQ）R=P（QR）*。因此，如果这些矩阵的大小是-*P*是 20×30，*Q*是 30×45，*R*是 45×50，那么*（PQ）R*和*P（QR）*的乘法数将是：

*   *（PQ）R*=20x30x45+20x45x50=72000
*   *P（QR）*=20x30x50+30x45x50=97500

从这个例子可以看出，如果我们使用第一个选项进行乘法，那么我们将需要 72000 次乘法，这与第二个选项相比要少一些/如下代码所示：

```py
def MatrixChain(mat, i, j):   
    if i == j:   
        return 0   
    minimum_computations = sys.maxsize  
    for k in range(i, j): 
        count = (MatrixChain(mat, i, k) + MatrixChain(mat, k+1, j)+ mat[i-1] * mat[k] * mat[j])   
        if count < minimum_computations:  
              minimum_computations= count;    
        return minimum_computations;  

matrix_sizes = [20, 30, 45, 50];  
print("Minimum multiplications are", MatrixChain(matrix_sizes , 1, len(matrix_sizes)-1));

#prints 72000
```

[Chapter 13](13.html), *Design Techniques and Strategies*, presents a more detailed discussion on the algorithm design strategy.

# 递归与回溯

递归对于分治问题特别有用；然而，很难准确地理解发生了什么，因为每个递归调用本身都与其他递归调用分离。递归函数可以位于无限循环中，因此，要求每个递归函数都遵守某些属性。递归函数的核心有两种情况：

*   **基本情况**：这些情况告诉递归何时终止，这意味着一旦满足基本条件，递归将停止
*   **递归案例**：函数调用自身，我们朝着基本标准前进

计算阶乘是一个简单的问题，它自然适合于递归解决方案。递归阶乘算法定义了两种情况：*n*为零时的基本情况（终止条件），以及*n*大于零时的递归情况（函数本身的调用）。典型的实现方式如下所示：

```py
def factorial(n): 
    # test for a base case      
    if  n==0: 
        return 1 
        #make a calculation and a recursive call
    else: 
        f= n*factorial(n-1) 
    print(f) 
    return(f) 

factorial(4)
```

为了计算`4`的阶乘，我们需要四个递归调用加上初始父调用。在每次递归中，方法变量的副本存储在内存中。一旦该方法返回，它将从内存中删除。以下是我们可以可视化此过程的方法：

对于一个特定的问题，递归或迭代是否是更好的解决方案并不一定很清楚；毕竟，它们都重复一系列操作，并且都非常适合分治方法和算法设计。迭代不断地进行，直到问题解决为止。递归将问题分解成越来越小的块，然后合并结果。迭代对于程序员来说通常更容易，因为控制保持在循环的局部，而递归可以更接近地表示数学概念，如阶乘。递归调用存储在内存中，而迭代不存储在内存中。这将在处理器周期和内存使用之间进行权衡，因此选择使用哪个周期可能取决于任务是处理器密集型任务还是内存密集型任务。下表概述了递归和迭代之间的主要区别：

| **递归** | **迭代** |
| 函数调用自身。 | 一组指令在循环中重复执行。 |
| 当满足终止条件时停止。 | 当满足循环条件时，它停止执行。 |
| 无限递归调用可能会产生与堆栈溢出相关的错误。 | 无限迭代将无限期运行，直到硬件通电。 |
| 每个递归调用都需要内存空间。 | 每个迭代不需要内存存储。 |
| 一般来说，代码大小相对较小。 | 一般来说，代码大小相对较小。 |
| 递归通常比迭代慢。 | 它速度更快，因为它不需要堆栈。 |

# 回溯

回溯是一种递归形式，对于遍历树结构之类的问题特别有用，在树结构中，每个节点都有许多选项，我们必须从中选择一个。随后，我们将看到一组不同的选项，根据所做的一系列选择，要么达到目标状态，要么达到死胡同。如果是后者，我们必须回溯到前一个节点并遍历另一个分支。回溯是一种用于穷举搜索的分治方法。重要的是，回溯**修剪**无法给出结果的分支。

下面给出一个回溯的例子。在这里，我们使用递归方法生成给定长度`n`的给定字符串`s`的所有可能排列：

```py
def bitStr(n,s):
 if n==1: return s 
 return [digit + bits for digit in bitStr(1,s) for bits in bitStr(n-1,s)] 

print(bitStr(3,'abc'))
```

这将生成以下输出：

![](Images/933bcc38-2e75-47b4-917e-7d5ee731f5b7.png)

注意这个理解中的双列表压缩和两个递归调用。这将递归地连接初始序列的每个元素（当*n*=1 时返回），以及在上一次递归调用中生成的字符串的每个元素。从这个意义上说，它是*回溯*来发现以前未生成的组合。返回的最后一个字符串是初始字符串的所有*n*字母组合。

# 分而治之——长乘法

为了使递归不仅仅是一个聪明的技巧，我们需要了解如何将它与其他方法（如迭代）进行比较，并了解何时使用它将导致更快的算法。我们都熟悉的一种迭代算法是我们在小学数学课上学习的，用于两个大数相乘的过程。那是长乘法。如果您还记得，长乘法包括迭代乘法和进位运算，然后是移位和加法运算。

我们的目的是研究如何衡量这个过程的效率，并试图回答这样一个问题：这是我们可以用来将两个大数字相乘的最有效的过程吗？

在下图中，我们可以看到两个四位数相乘需要 16 个乘法运算，我们可以概括说一个*n*位数大约需要*n*<sup>*2*</sup>乘法运算：

![](Images/0bc9b9a7-2672-436c-b651-f1d56260339c.png)

根据乘法和加法等计算原语的数量，这种分析算法的方法非常重要，因为它为我们提供了一种了解完成某一计算所需时间与该计算输入大小之间关系的方法。特别是，我们想知道当输入的位数*n*非常大时会发生什么。这一主题被称为**渐近分析**或**时间复杂度**，对我们研究算法至关重要，我们将在本章和本书的其余部分经常重温这一主题。

# 递归方法

事实证明，在长乘法的情况下，答案是肯定的，事实上有几种大数乘法算法需要较少的运算。最著名的长乘法替代方法之一是 1962 年首次发表的**Karatsuba 算法**。这采用了一种根本不同的方法：它不是对单个数字进行迭代乘法，而是对逐渐减小的输入进行递归乘法运算。递归程序在较小的输入子集上调用自己。构建递归算法的第一步是将一个大数分解为几个小数。最自然的方法是将数字分成两半，前半部分是最高有效数字，后半部分是最低有效数字。例如，我们的四位数 2345 变成了一对两位数 23 和 45。我们可以使用以下公式编写任意两个*n*数字、*x*和*y*的更一般分解，其中*m*是小于*n*的任何正整数：

![](Images/a3c99940-655a-414f-81bf-3f12983cecde.png)

![](Images/b3b0c275-29d8-4f19-a38d-f3b935180c21.png)

现在我们可以将乘法问题*x*、*y*重写如下：

![](Images/feea5e6e-0ba8-42af-820e-c61603ca563e.png)

当我们展开时，我们得到以下结果：

![](Images/31fa81b7-71ca-471f-a4a5-8d92229fc993.png)

更方便的是，我们可以这样写（方程式 3.1）：

![](Images/3eecd139-882e-4cf6-bfb1-1d89f560583b.png)。。。(3.1)

哪里：

![](Images/d46fac6b-adc9-4d6e-aeb8-efdf3c003ddd.png)

应该指出的是，这表明了两个数字相乘的递归方法，因为这个过程本身确实涉及乘法。具体而言，产品*ac*、*ad*、*bc*和*bd*都涉及比输入数字小的数字，因此可以想象，我们可以将相同的操作作为整体问题的部分解决方案。到目前为止，该算法由四个递归乘法步骤组成，目前还不清楚它是否比经典的长乘法方法更快。

到目前为止，我们讨论的关于乘法递归方法的内容，自十九世纪末以来就为数学家所熟知。Karatsuba 算法通过以下观察改进了这一点。我们真的只需要知道三个量：*z*<sub xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:epub="http://www.idpf.org/2007/ops">*2*</sub>=*ac*、*z*<sub xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:epub="http://www.idpf.org/2007/ops">*1*</sub>*=ad+bc*、*z**=T22】解方程 3.1。我们只需要知道*a*、*b*、*c*和*d*的值，只要它们对计算数量*z*<sub xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:epub="http://www.idpf.org/2007/ops">【T35 2】</sub>、*z*<sub xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:epub="http://www.idpf.org/2007/ops">所涉及的总和和乘积有贡献*1*</sub>、*z*<sub xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:epub="http://www.idpf.org/2007/ops">*0*</sub>。这表明我们可能可以减少递归步骤的数量。事实证明，情况确实如此。*

 *由于产品*ac*和*bd*已经是最简单的形式，我们似乎不太可能消除这些计算。然而，我们可以作出以下观察：

![](Images/88959a91-37a3-4a23-93c4-083e43baa17a.png)

当我们减去前面递归步骤中计算的数量*ac*和*bd*时，我们得到了我们需要的数量，即（*ad+bc*：

![](Images/4d502318-8937-4c95-a555-5be65f889dce.png)

这表明我们确实可以计算*ad+bc*之和，而无需单独计算每个量。总之，我们可以通过将四个递归步骤减少到三个来改进等式 3.1。这三个步骤如下：

1.  递归计算*ac*
2.  递归计算*bd*
3.  递归计算（*a+b*（*c+d*）并减去*ac*和*bd*

下面的示例显示了 Karatsuba 算法的 Python 实现。在下面的代码中，我们首先看到，如果给定的数字中有任何一个小于 10，那么就不需要运行递归函数。接下来，我们确定较大值中的位数，如果位数为奇数，则添加一个。最后，我们递归调用该函数三次来计算*ac*、*bd*、*a+d*（*c+d*）。以下代码打印任意两位数字的乘法；例如，它打印`4264704`用于`1234`和`3456`的乘法。Karatsuba 算法的实现是：

```py
from math import log10 
def karatsuba(x,y): 

    #The base case for recursion 
    if x<10 or y<10:
        return x*y 

    #sets n, the number of digits in the highest input number
    n=max(int(log10(x)+1), int(log10(y)+1)) 

    #rounds up n/2  
    n_2 = int(math.ceil(n/2.0)) 
    #adds 1 if n is uneven  
    n = n if n%2 == 0  else n+1 
    #splits the input numbers 
    a, b = divmod(x, 10**n_2) 
    c, d = divmod(y,10**n_2) 
    #applies the three recursive steps 
    ac = karatsuba(a,c) 
    bd = karatsuba(b,d)  
    ad_bc = karatsuba((a+b),(c+d))-ac-bd 

    #performs the multiplication 
    return (((10**n)*ac)+bd+((10**n_2)*(ad_bc)))

t= karatsuba(1234,3456)
print(t)

# outputs - 4264704
```

# 运行时分析

算法的性能通常由其输入数据的大小（**n**）以及算法使用的时间和内存空间来衡量。**所需时间**由算法执行的关键操作（如比较操作）来衡量，而算法的空间需求则由程序执行期间存储变量、常量和指令所需的存储来衡量。算法的空间需求也可能在执行过程中动态变化，因为它取决于可变大小，可变大小将在运行时确定，例如动态内存分配、内存堆栈等。

算法所需的运行时间取决于输入大小；随着输入大小（**n**的增加，运行时间也会增加。例如，与另一个输入大小为 50 的列表相比，排序算法将有更多的运行时间对输入大小为 5000 的列表进行排序。因此，很明显，要计算时间复杂度，输入大小很重要。此外，对于特定输入，运行时间取决于算法中要执行的关键操作。例如，排序算法的关键操作是一个**比较操作**，与赋值或任何其他操作相比，它将占用大部分时间。要执行的关键操作的数量越多，运行算法所需的时间就越长。

应该注意的是，算法设计的一个重要方面是从空间（内存）和时间（操作数）两方面衡量效率。应该提到的是，使用相同的度量来衡量算法的内存性能。可以想象，有很多方法可以测量运行时，最明显的方法可能是简单地测量算法所花费的总时间。这种方法的主要问题是，算法运行所需的时间在很大程度上取决于它所运行的硬件。衡量算法运行时间的一种与平台无关的方法是计算所涉及的操作数。然而，这也是有问题的，因为没有确定的方法来量化操作。这取决于编程语言、编码风格以及我们决定如何计算操作。但是，如果我们将计数操作的思想与期望结合起来，即随着输入的大小增加，运行时将以特定的方式增加，那么我们就可以使用这种想法。也就是说，*n*与输入的大小以及算法运行所需的时间之间存在数学关系。算法的运行时性能主要有三个特征：；这些可以描述如下：

*   最坏情况复杂度是上界复杂度；它是执行算法所需的最大运行时间。在这种情况下，键操作将执行最大次数。
*   最佳情况复杂度是下界复杂度；它是执行算法所需的最短运行时间。在这种情况下，密钥操作将被执行最少的次数。
*   Average case complexity 是算法执行所需的平均运行时间。

最坏情况分析很有用，因为它给了我们一个严格的上界，我们的算法保证不会超过这个上界。忽略小的常数因子和低阶项实际上就是忽略在输入大小*n*的较大值下，在很大程度上对总体运行时间没有贡献的东西。这不仅使我们的工作在数学上更容易，而且使我们能够专注于对性能影响最大的事情。

我们在 Karatsuba 算法中看到，乘法运算的数量增加到输入的大小*n*的平方。如果我们有一个四位数，乘法运算的次数是 16；八位数需要 64 次运算。但通常，我们对*n*的小值下的算法行为并不感兴趣，因此我们通常忽略以较慢速率增加的因素，比如与*n*线性增加的因素。这是因为在*n*的高值下，随着*n*的增加，增长最快的操作将占主导地位。

我们将用一个例子更详细地解释这一点：合并排序算法。排序是[第 10 章](10.html)、*排序*的主题，但是，作为一种先兆和了解运行时性能的有用方法，我们将在这里介绍合并排序。

合并排序算法是 60 多年前开发的经典算法。它仍然在许多最流行的排序库中广泛使用。这是相对简单和有效的。这是一种使用分治方法的递归算法。这涉及到将问题分解成更小的子问题，递归地解决它们，然后以某种方式组合结果。合并排序是分而治之范式最明显的演示之一。

合并排序算法由三个简单步骤组成：

1.  对输入数组的左半部分进行递归排序
2.  对输入数组的右半部分进行递归排序
3.  将两个已排序的子数组合并为一个

一个典型的问题是将数字列表按数字顺序排序。合并排序的工作原理是将输入分成两半，并并行处理每一半。我们可以用下图示意性地说明这一过程：

以下是合并排序算法的 Python 代码：

```py
def mergeSort(A): 
#base case if the input array is one or zero just return. 
if len(A) > 1: 
    # splitting input array 
    print('splitting ', A ) 
    mid=len(A)//2   
    left=A[:mid]   
    right=A[mid:] 
    #recursive calls to mergeSort for left and right subarrays 
    mergeSort(left)   
    mergeSort(right) 
    #initalizes pointers for left(i) right(j) and output array (k)

    #3 initalization operations 
    i = j = k = 0 
    #Traverse and merges the sorted arrays 
    while i < len(left) and j < len(right):  
    #if left < right comparison operation 
        if left[i] < right[j]:  
        #if left < right Assignment operation  
            A[k] = left[i]  
            i=i+1 
        else:   
            #if right <= left assignment 
            A[k]=right[j] 
            j=j+1   
            k=k+1   

    while i< len(left):   
    #Assignment operation 
        A[k] = left[i] 
        i=i+1   
        k=k+1   

    while j< len(right):   
    # Assignment operation    
        A[k] = right[j] 
        j=j+1 
        k=k+1 

print('merging',A) 
return(A)
```

我们运行此程序以获得以下结果：

![](Images/d2f8424e-f06e-47ff-ac59-5a0d32a0f06f.png)

我们感兴趣的问题是如何确定运行时性能，即相对于*n*的大小，算法完成所需时间的增长率是多少？为了更好地理解这一点，我们可以将每个递归调用映射到树结构上。树中的每个节点都是一个递归调用，处理逐渐变小的子问题：

![](Images/40e4b2b0-3c6a-4630-8f5d-643da4b7210c.png)

每次调用 merge-sort 都会创建两个递归调用，因此我们可以用二叉树来表示这一点。每个子节点接收输入的子集。最后，我们想知道相对于*n*的大小，算法完成所需的总时间。首先，我们可以计算树的每个级别上的工作量和操作数。

以运行时分析为重点，在一级将问题分解为两个子问题*n*/2；在二级，有四个*n*/4 子问题，以此类推。问题是，递归何时见底，即何时到达其基本情况？这只是当数组为 0 或 1 时。

递归级别的数量正是你需要将*n*除以 2 的次数，直到你得到一个最多为 1 的数字。这正是 log2 的定义。由于我们将初始递归调用计数为零级，因此总级别数为 log<sub>2</sub>*n*+1。

让我们停下来完善我们的定义。到目前为止，我们已经用字母*n*描述了输入中的元素数量。这是指递归第一级中的元素数量，即初始输入的长度。我们需要在后续递归级别区分输入的大小。为此，我们将使用字母*m*或具体的*m*<sub>*j*</sub>作为递归级别*j 的输入长度。*

此外，还有一些我们忽略了的细节，我相信你们已经开始怀疑了。例如，当*m*/2 不是整数，或者输入数组中存在重复项时，会发生什么情况？事实证明，这对我们这里的分析没有重要影响；我们将在[第 12 章](13.html)、*设计技术和策略*中回顾合并排序算法的一些更详细的细节。

使用递归树分析算法的优点是，我们可以计算在递归的每个级别上所做的工作。我们如何定义这项工作仅仅是通过操作的总数，当然，这与输入的大小有关。以独立于平台的方式测量和比较算法的性能非常重要。当然，实际运行时将取决于运行它的硬件。计算操作数很重要，因为它为我们提供了一个与算法性能直接相关的度量，与平台无关。

一般来说，由于 merge-sort 的每次调用都会进行两次递归调用，因此每个级别的调用数量都会翻倍。同时，这些调用中的每一个都在处理一个输入，该输入是其父级的一半。我们可以将其形式化，并说对于级别*j*，其中*j*是一个整数*0，1，2。。。日志<sub>2</sub>n*，有两个子问题，每个子问题的大小为*n/2<sup>j</sup>*。

要计算操作总数，我们需要知道两个子数组的单个合并所包含的操作数。让我们统计一下前面 Python 代码中的操作数。我们感兴趣的是两次递归调用之后的所有代码。首先，我们有三个赋值操作。接下来是三个`while`循环。在第一个循环中，我们有一个 if-else 语句，在两个操作中的每个操作中，都有一个比较，然后是赋值。由于 if-else 语句中只有一组操作，因此我们可以将此代码块计算为执行了*m*次的两个操作。接下来是两个`while`循环，每个循环都有一个赋值操作。这使得合并排序的每个递归总共有*4m+3*个操作。

由于*m*必须至少是一个，所以操作数的上限为 7*m*。必须说，这并不是一个精确的数字。当然，我们可以决定以不同的方式计算操作数。我们没有计算增量操作或任何内务操作；然而，这并不重要，因为我们更关心的是在*n*的高值下*n*的运行时增长率。

这似乎有点让人望而生畏，因为递归调用本身的每次调用都会派生出更多的递归调用，并且似乎呈指数级增长。使其易于管理的关键事实是，当递归调用的数量翻倍时，每个子问题的大小会减半。正如我们可以证明的那样，这两种相反的力量相互抵消得很好。

为了计算递归树每个级别上的最大操作数，我们只需将子问题数乘以每个子问题中的操作数，如下所示：

![](Images/f963cdb9-6851-4a7b-9ee5-a7437f7c0f5c.png)

重要的是，这表明，因为*2<sup>j</sup>*取消了每个级别上的操作数，所以该操作数与该级别无关。这为我们提供了每个级别上执行的操作数的上限，在本例中为 7*n*。应该指出的是，这包括在该级别上每个递归调用执行的操作数，而不是在后续级别上执行的递归调用数。这表明工作已经完成，因为递归调用的数量随着每个级别的增加而增加了一倍，而每个子问题的输入大小减半的事实正好抵消了这一点。

要查找完整合并排序的操作总数，只需将每个级别上的操作数乘以级别数即可。这给了我们以下信息：

![](Images/e06dc99e-5e0a-4f6b-829f-2ad033c7a5ed.png)

当我们将其展开时，我们得到以下结果：

![](Images/d0ad8584-5760-4081-aac4-65ab789871f5.png)

从中得出的关键点是，输入大小与总运行时间之间存在对数关系。如果你还记得学校数学的话，对数函数的显著特点是它很快变平。作为输入变量，*x*的大小增加；输出变量*y*的增加量越来越小。

例如，将对数函数与线性函数进行比较：

![](Images/a70898f7-13ed-4b6b-92d4-a71a04c40e64.png)

在上例中，将*n*log<sub>2</sub>n*n*分量相乘并与![](Images/2b34c45d-a9f3-4b96-8893-66994aba5875.png)进行比较：

![](Images/66071838-ae0b-4bb1-b942-01638c4ef2e2.png)

请注意，对于非常低的*n*值，对于在 n2 时间内运行的算法，完成时间*t*实际上较低。然而，对于大于 40 的值，log 函数开始占主导地位，使输出变得平坦，直到在相对适中的大小*n*=100 时，性能比在*n*<sup>2</sup>时间内运行的算法高出一倍以上。还要注意的是，常数因子+7 的消失在*n*的高值下是不相关的。

用于生成这些图形的代码如下所示：

```py
import matplotlib.pyplotasplt 
import math   
x = list(range(1,100))   
l=[]; l2=[]; a=1   
plt.plot(x, [y*y for y in x])  
plt.plot(x, [(7*y)*math.log(y,2) for y in x]) 
plt.show()
```

如果`matplotlib`库尚未安装，则需要安装该库才能正常工作。详情可在以下地址找到；我鼓励您尝试使用这个列表理解表达式来生成图。例如，我们可以添加以下`plot`语句：

```py
plt.plot(x, [(6*y)* math.log(y, 2) for y in x])
```

这将提供以下输出：

![](Images/4a4614bc-1fd3-49e5-ad08-f9c7ce354585.png)

上图显示了计算六个操作或七个操作之间的差异。我们可以看到这两种情况是如何分歧的，这在我们讨论应用程序的细节时很重要。然而，我们更感兴趣的是一种描述增长率的方法。我们不太关心绝对值，而是随着*n*的增加，这些值是如何变化的。这样，我们可以看到，与顶部（*x*<sup>2</sup>曲线相比，两条较低的曲线具有相似的增长率。我们说这两条较低的曲线具有相同的**复杂度等级**。这是一种理解和描述不同运行时行为的方法。我们将在下一节中正式确定此性能指标。

# 渐近分析

算法的渐近分析是指计算算法的运行时间。为了确定哪种算法更好，给定两种算法，一种简单的方法是运行两个程序，对于给定的输入，执行时间最短的算法比另一种算法更好。然而，对于特定的输入，一种算法的性能可能优于另一种，而对于任何其他输入值，该算法的性能可能更差。

在渐近分析中，我们比较了两种算法的输入大小，而不是实际运行时间，并且我们测量了所花费的时间如何随着输入大小的增加而增加。以下代码对此进行了描述：

```py
# Linear search program to search an element, return the index position of the #array
def searching(search_arr, x):     
    for i in range(len(search_arr)):         
        if search_arr [i] == x:             
                return i     
    return -1

search_ar= [3, 4, 1, 6, 14]
x=4

searching(search_ar, x)
print("Index position for the element x is :",searching(search_ar, x))

#outputs index position of the element x that is - 1
```

假设数组的大小为`n`，且*T（n）*是执行线性搜索所需的键操作总数，则本例中的键操作为比较。让我们以线性搜索为例来了解最坏情况、平均情况和最佳情况复杂性：

*   最坏情况分析：T1 席：考虑上限运行时间，即算法所需的最大时间。在线性搜索中，最坏的情况发生在最后一次比较中找到要搜索的元素或在列表中找不到该元素时。在这种情况下，将有最大数量的比较，这将是数组中元素的总数。因此，最坏情况下的时间复杂度为Θ（n）。
*   在这一分析中，我们考虑席中可以找到元素的所有可能情况，然后计算平均运行时间复杂度。例如，在线性搜索中，如果要搜索的元素在*0th*索引处找到，则所有位置的比较次数将为*1*，同样，在*1、2、3、…（n-1）处找到的元素的比较次数将为 2、3 等等，分别高达*n**索引位置*因此平均时间复杂度可以定义为`average-case complexity= (1+2+3…n)/n = n(n+1)/2`。*
**   **最佳案例分析**：最佳案例运行时间复杂度是算法运行所需的最短时间；它是下限运行时间。在线性搜索中，最好的情况是在第一次比较中找到要搜索的元素。在本例中，很明显，最佳情况时间复杂度并不取决于列表的长度。因此，最佳情况下的时间复杂度为*Θ（1）*。*

 *通常，我们使用最坏情况分析来分析算法，因为它为我们提供了运行时间的上限，而最佳情况分析最不重要，因为它为我们提供了下限，即算法所需的最短时间。此外，平均案例分析的计算非常困难。

为了计算每一个，我们需要知道上界和下界。我们研究了一种使用数学表达式表示算法运行时的方法，本质上是加法和乘法运算。为了使用渐近分析，我们只需创建两个表达式，最好和最坏情况各一个。

# 大 O 符号

大的*O*符号中的字母 O 代表顺序，因为增长率被定义为函数的顺序。它度量最坏情况下的运行时间复杂度，即算法所需的最大时间。我们说一个函数*T*（*n*）是另一个函数*F*（*n*）的大 O，我们定义如下：

![](Images/ca98e7da-6adf-45dd-bb3d-2d818e74f5b1.png)

输入大小*n*的函数*g*（*n*）基于以下观察结果：对于*n*的所有足够大的值，*g*（*n*在上面以*f*（*n*的常数倍数为界。目标是找到小于或等于*f*（*n*的最小增长率）。我们只关心*n*的较高值会发生什么。变量*n**0*表示增长率不重要的阈值。函数*T（n）*表示**紧上界**F（n）。在下面的情节中，我们可以看到*T**n*=*n*<sup xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:epub="http://www.idpf.org/2007/ops">*2*</sup>+500=*O**n*<sup xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:epub="http://www.idpf.org/2007/ops">*2*</sup>、与*C*=2 和*n<sub xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:epub="http://www.idpf.org/2007/ops">****一起****</sub>*约为 23：

![](Images/34695609-21eb-4181-ad54-229cd55006af.png)

您还将看到符号*f*（*n*）=*O*（*g*（*n*）。这说明了*O*（*g*（*n*）实际上是一组函数，其中包括所有具有与*f*（n）相同或更小增长率的函数。例如，O.Ty18To（To 20Tn，n，T21，T22），T23（2），也包括函数 T26，O（n），T27，So，T28，O（NLogn），T29，等等。

函数`f(x)= 19n log<sub>2</sub>n  +56 `的大 O 时间复杂度为*O（nlogn）*。

在下表中，我们按从最低到最高的顺序列出了最常见的增长率。我们有时将这些增长率称为函数的**时间复杂度**，或函数的复杂度等级：

| **复杂度等级** | **名称** | **示例操作** |
| *O（1）* | 常数 | 追加、获取项目、设置项目。 |
| *O（logn）* | 对数的 | 在排序数组中查找元素。 |
| *O（n）* | 线性的 | 复制、插入、删除、迭代。 |
| *nLogn* | 线性对数 | 对列表排序，合并排序。 |
| *n*<sup>*2*</sup> | 二次的 | 查找图中两个节点之间的最短路径。嵌套循环。 |
| *n*<sup>*3*</sup> | 立方体的 | 矩阵乘法。 |
| 2<sup>*n*</sup> | 指数型 | **河内塔楼**问题，回溯。 |

# 组成复杂类

通常，我们需要找到一些基本操作的总运行时间。事实证明，我们可以组合简单操作的复杂性类，以找到更复杂的组合操作的复杂性类。目标是分析函数或方法中的组合语句，以了解执行多个操作的总时间复杂度。组合两个复杂类的最简单方法是添加它们。当我们有两个连续的操作时，就会发生这种情况。例如，考虑将一个元素插入列表并排序该列表的两种操作。我们可以看到插入项发生在*O（n）*时间，排序发生在*O（nlogn）*时间。我们可以将总时间复杂度写为*O（n+nlogn）*，也就是说，我们将这两个函数放在*O（…）*中。我们只对最高阶项感兴趣，因此只剩下*O（nlogn）*。

如果我们重复一个操作，例如，在一个`while`循环中，那么我们将复杂性类乘以执行该操作的次数。如果一个时间复杂度为*O（f（n））*的操作重复了*O（n）*次，那么我们将两个复杂度相乘：

![](Images/4e850cfb-5448-44c5-976f-747b075798b0.png)

例如，假设函数`f(...)`的时间复杂度为*O（n<sup>2</sup>*，在`while`循环中执行*n*次，如下所示：

```py
for i in range(n): 
        f(...)
```

该循环的时间复杂度随后变为*O（n<sup>2</sup>）*O（n）=O（n*n<sup>2</sup>）=O（n<sup>3</sup>*。这里我们只是将操作的时间复杂度乘以该操作执行的次数。循环的运行时间最多是循环内语句的运行时间乘以迭代次数。假设两个循环都运行`n`次，则单个嵌套循环（即一个循环嵌套在另一个循环中）将在*n*2 次内运行，如下例所示：

```py
for i in range(0,n): 
    for j in range(0,n)  
            #statements
```

每个语句都是一个常量，*c*，执行*nn*次，因此我们可以将运行时间表示为：

![](Images/252c1e30-173c-4958-923c-369eb1bc0fcb.png)

对于嵌套循环中的连续语句，我们将每个语句的时间复杂度相加，然后乘以语句执行的次数，例如：

```py
n=500  #c0 
#executes n times  
for i in range(0,n):  
    print(i)    #c1
   #executes n times   
for i in range(0,n):  
#executes n times  
    for j in range(0,n):  
            print(j)  #c2
```

这可以写为`c<sub>0</sub> +c<sub>1 </sub>n + cn<sup>2 </sup>= O(n<sup>2</sup>)`。

我们可以定义（基数 2）对数复杂度，在恒定时间内将问题的大小减少½。例如，考虑下面的片段：

```py
i=1   
while i<=n: 
    i=i*2 
    print(i)   
```

请注意，我在每次迭代中加倍；如果我们在*n*=10 的情况下运行它，我们会看到它打印出四个数字：2、4、8 和 16。如果我们把*n*加倍，我们会看到它打印出五个数字。随着*n*的每一次后续加倍，迭代次数仅增加一次。如果我们假设*k*迭代，我们可以这样写：

![](Images/b31931aa-a8aa-451c-b30c-b8590dfcf074.png)

![](Images/7ed3d882-ac80-4bc2-93b7-5c00efc6350d.png)

![](Images/8ab8d784-60cc-4838-9816-7f1c9269a84e.png)

由此可以得出总时间=***O**（log（n））*。

虽然大 O 是渐近分析中最常用的符号，但还有两个相关的符号需要简要提及。它们是ω表示法和θ表示法。

# 欧米茄符号(Ω)

Omega 表示法描述了算法的紧下界，类似于描述紧上界的大 O 表示法。Omega 表示法计算算法的最佳运行时间复杂性。它提供了最高的增长率*T（n）*，小于或等于给定的算法。它可以计算如下：

![](Images/69e1d0c6-1542-4193-be5e-5e43ebcbc465.png)

# θ表示法（ϴ）

通常情况下，给定函数的上界和下界相同，θ表示法的目的是确定是否存在这种情况。定义如下：

![](Images/391dc9e6-d17d-40c8-a353-f80e5b7576e9.png)

虽然完全描述增长率需要ω和θ符号，但最实用的是大 O 符号，这是您最常看到的符号。

# 摊销分析

我们通常对单个操作的时间复杂性不太感兴趣；我们更感兴趣的是操作序列的平均运行时间。这称为摊销分析。它不同于我们稍后将讨论的平均案例分析，因为我们不对输入值的数据分布进行假设。然而，它考虑了数据结构的状态变化。例如，如果列表已排序，则任何后续查找操作都应该更快。摊销分析考虑数据结构的状态变化，因为它分析操作序列，而不是简单地聚合单个操作。

摊销分析描述了算法运行时的上限；它对算法中的每个操作都施加了额外的成本。与最初昂贵的操作相比，序列的额外考虑成本可能更便宜

当我们有少量昂贵的操作（如排序）和大量便宜的操作（如查找）时，标准的最坏情况分析可能会导致过于悲观的结果，因为它假设每次查找都必须比较列表中的每个元素，直到找到匹配项。我们应该考虑到，一旦我们对列表进行排序，我们就可以使后续的查找操作更便宜。

到目前为止，在我们的运行时分析中，我们假设输入数据是完全随机的，只考虑了输入大小对运行时的影响。还有两种常见的算法分析方法；他们是：

*   平均案例分析
*   标杆管理

平均案例分析将发现基于各种输入值相对频率的一些假设的平均运行时间。使用真实世界数据或复制真实世界数据分布的数据在特定数据分布上会重复多次，并计算平均运行时间。

基准管理就是简单地拥有一组商定的典型输入，用于衡量绩效。基准测试和平均时间分析都依赖于具备一些领域知识。我们需要知道典型的或预期的数据集是什么。最后，我们将尝试通过微调到非常特定的应用程序设置来找到提高性能的方法。

让我们看一下一种测试算法运行时性能的简单方法。这可以通过简单地计时算法完成给定的各种输入大小所需的时间来完成。正如我们前面提到的，这种测量运行时性能的方法取决于它所运行的硬件。显然，更快的处理器将提供更好的结果，但是，随着输入大小的增加，相对增长率将保留算法本身的特性，而不是它运行在的硬件上。硬件（和软件）平台之间的绝对时间值不同；然而，它们的相对增长仍然受到算法时间复杂度的限制。

让我们举一个嵌套循环的简单例子。很明显，该算法的时间复杂度为*O（n<sup>2</sup>*，因为在外循环中每*n*次迭代，在 interloop 中也有*n*次迭代。例如，我们的简单嵌套 For 循环由在内部循环上执行的简单语句组成：

```py
def nest(n):   
for i in range(n):   
     for j in range(n):  
            i+j
```

下面的代码是一个简单的测试函数，它以`n`的递增值运行`nest`函数。在每次迭代中，我们使用`timeit.timeit`函数计算该函数完成所需的时间。在本例中，`timeit`函数有三个参数，一个是要计时的函数的字符串表示，一个是导入`nest`函数的`setup`函数，另一个是指示执行 main 语句的次数的`int`参数。

由于我们对`nest`函数相对于输入大小`n`完成所需的时间感兴趣，因此就我们而言，在每次迭代中调用`nest`函数一次就足够了。以下函数返回`n`每个值的计算运行时列表：

```py
import timeit 
def test2(n): 
    ls=[]   
    for n in range(n):
        t=timeit.timeit("nest(" + str(n) + ")", setup="from _main_ import nest", number=1)  
        ls.append(t) 
    return ls
```

在下面的代码中，我们运行`test2`函数并将结果与适当缩放的`n<sup>2</sup>`函数一起绘制图表，以进行比较，用虚线表示：

```py
import matplotlib.pyplot as plt 
n=1000 
plt.plot(test2(n)) 
plt.plot([x*x/10000000 for x in range(n)])
```

这将产生以下结果：

![](Images/0f25b101-61b9-454e-9adb-9f8774b28063.png)

正如我们所看到的，这给了我们很大的期望。应该记住，这既代表了算法本身的性能，也代表了底层软件和硬件平台的行为，如测量运行时的可变性和运行时的相对大小所示。显然，更快的处理器会导致更快的运行时间，而且性能还会受到其他运行进程、内存限制、时钟速度等的影响。

# 总结

在本章中，我们对算法设计进行了概述。重要的是，我们研究了一种独立于平台的方法来衡量算法的性能。我们研究了一些解决算法问题的不同方法。我们研究了一种递归乘法大数的方法，以及一种用于合并排序的递归方法。我们学习了如何使用回溯进行穷举搜索和生成字符串。我们还介绍了基准测试的思想和一种简单的依赖于平台的运行时度量方法。

在接下来的章节中，我们将参考特定的数据结构，重新讨论其中的许多想法。在下一章中，我们将讨论链表和其他指针结构。**